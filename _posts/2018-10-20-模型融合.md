---
layout:     post
title:      模型融合方法
subtitle:   
date:       2018-10-20
author:     ColaFei
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - Git
---

> 最后更新于10月20日

从《美团机器学习实践》中根据个人理解总结的几种主流的模型融合方法

## ``` 平均法 ```

基本思路是：对多个回归模型的数值型输出进行平均，把平均后的结果作为融合模型的输出。

围绕一个回归问题，训练了T个单模型{h1,h2,...,ht}，其中对于样本x，hi的输出为hi(x)∈R。这个单模型集合有可能包含
多个类型的模型（异质模型），比如线性模型、树模型或者神经网络，也有可能存在同一类型模型但是采用参数或特征集合
有差异（同质模型）。

我们要做的是融合这T个单模型来获得最终的样本预测值。

``` 平均法 ```是把单模型的输出进行加权平均。设融合模型为：
![](https://upload-images.jianshu.io/upload_images/13880974-21bc236ec12d6c45.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

其中，wi表示单模型hi的权重，一般情况下，要求wi>=0，所有wi的和为1.这个权重其实表征了单模型的重要程度，
wi=1/T时，则单模型在融合过程中的重要性是等价的，这是最简单的``` 简单平均法 ```，它是``` 加权平均法 ```的一个特例。

经过计算得到验证，简单平均法得到的融合模型误差小于等于单模型的平均误差。

当单模型权重wi不相等时，平均法就是常规的``` 加权平均法 ```。一般来说，预测效果好的单模型权重应该设置
大一些，表现稍差的单模型权重设置小一些。

从``` 经验角度 ```来看，这样简单人工指定模型权重，很大概率能够取得很不错的效果。

从``` 集成学习角度 ```来看，加权平均法的权重也可以从训练数据中学习而得。把单模型权重作为变量，
通过一些优化方法找到最优解，但是一般情况下是不可行的。因为现实的机器学习任务中的训练样本通常不充分
或存在噪声，这将使得学习的权重并不完全可靠。尤其是对规模较大的集成来说，要学习的权重比较多，这很容易
导致过拟合。因此，实际和应用均显示，加权平均法未必一定优于简单平均法。

广泛认可的一个策略是：当单模型性能表现比较一致时，采用简单平均法比较好；当单模型差异性比较大时，采用不同权重的加权平均法更适宜。

## ``` 投票法 ```

对于分类任务来说，模型hi需要从类别标记集合{c1,...,cl}中预测出一个标记，投票法是一种常见的解决分类任务的模型融合的策略。

围绕一个分类问题，训练了T个单模型{h1,h2,...,hT}，这些单模型可能是不同算法训练出来的异质模型，也有可能是不同特征或不同参数
得到的同质模型。我们的目标是，融合这T个单模型从l个类别标记中预测出一个标记。

为描述方便，我们假设对于每一个样本x，模型hi最终给出一个l维的标记向量:
![](https://upload-images.jianshu.io/upload_images/13880974-8e4a14c261f1c4d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

## ``` Bagging ```
是称得上是


## ``` Stacking ```



