---
layout:     post
title:      机器学习知识点整理
subtitle:   面试
date:       2019-3-20
author:     Colafei
header-img: img/post-bg-debug.png
catalog: true
tags:
    - Git
---


>最后更新于2019年3月20日

## 损失函数

损失函数：表征模型预测值与真实值的不一致程度。记为函数L(Y,f(X))

结构风险函数 = 经验风险项  +  正则项  其中损失函数为经验风险项的重要组成部分

前半部分为经验风险项，后半部分为正则项。

#### 对数损失函数

P(Y|X)为样本为Y的概率，数值越大说明预测值与真实值越接近即损失函数应该越小，当P（Y|X）越大的，-logP(Y|X)越小，刚好符合损失函数的定义。



#### 平方损失函数


#### 指数损失函数


#### HInge损失函数


#### 0-1损失函数


#### 绝对值损失函数


#### 模型的优缺点

``` 缺点：```

需要大量样本，因为最大似然估计在低样本量的情况下不如最小二乘法有效；

对变量的相关性比较敏感，需要对自变量进行相关性分析，提出线性相关的变量；

为了防止过拟合和欠拟合，模型构建的变量必须是显著的。

``` 优点：```

模型比较简单，好理解，实现大规模线性分类时比较方便


## GBDT 
#### 原理

gbdt并基于gradient boosting学习到一组决策树，即CART。

#### 模型的使用场景

GBDT用来做回归预测，调整后也可以用于分类（设定阈值，大于阈值为正例，反之为负例）

## XGBoost 

#### 原理

一个基于预排序的boosting决策树模型，在对数据进行训练之前，预先对数据进行了预排序，叶子生长方式是level-wise，。

#### 模型的使用场景

可以用来做回归，也可以做分类；xgboost的基学习器也可以是线性的，可以做线性回归，线性分类，多分类等。

#### 防止过拟合

借鉴了随机森林的思想，可以使用列采样来防止过拟合。


## LightGBM(lgb)
#### 原理

#### 模型的使用场景






	


