---
layout:     post
title:      机器学习知识点整理
subtitle:   面试
date:       2019-3-20
author:     Colafei
header-img: img/post-bg-debug.png
catalog: true
tags:
    - Git
---


>最后更新于2019年3月20日

## 损失函数

损失函数：表征模型预测值与真实值的不一致程度。记为函数L(Y,f(X))

结构风险函数 = 经验风险项  +  正则项  其中损失函数为经验风险项的重要组成部分

前半部分为经验风险项，后半部分为正则项。

#### 对数损失函数

![](/img/post/20190320/1.png)
P(Y|X)表示样本为Y的概率，数值越大说明预测值与真实值越接近即损失函数应该越小，当P（Y|X）越大的，-logP(Y|X)越小，刚好符合损失函数的定义。



#### 交叉熵损失函数

![](/img/post/20190320/12.png)

``` LR逻辑回归 ```损失函数即为交叉熵损失函数

#### 平方损失函数

![](/img/post/20190320/2.png)

在``` 线性回归 ```中，使用的是平方损失函数，它假设样本和噪声都服从高斯分布（中心极限定理），最后通过极大似然估计（MLE）可以推导出最小二乘式子。

![](/img/post/20190320/3.png)

#### 指数损失函数

![](/img/post/20190320/4.png)
AdaBoost中损失函数为：

![](/img/post/20190320/5.png)
#### Hinge损失函数

用于最大间隔（maximum-margin）分类，其中最有代表性的就是支持向量机SVM。

![](/img/post/20190320/6.png)

其中 y=+1或y=−1，f(x)=wx+b，当为SVM的线性核时。

``` SVM ```中损失函数即为Hinge损失函数：
![](/img/post/20190320/7.png)
![](/img/post/20190320/8.png)

进而变形为：
![](/img/post/20190320/9.png)

#### 0-1损失函数
![](/img/post/20190320/10.png)

#### 绝对值损失函数
![](/img/post/20190320/11.png)








	


